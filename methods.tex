
First in this section the corpus and the method for building the corpus are introduced. Then
a new web-based application for collaborative metaphor annotation and coding 
is introduced.  This tool allows for efficient export, including a data 
analysis pipeline API for custom Python applications.  
The methods for data export and analysis are demonstrated. Finally, the
statistical methods used for finding the phase transitions in figurative 
violence use are discussed.

\subsection{Corpus}
\label{subsec:Corpus}

The corpus is a set of 607 transcripts from cable news shows aired from
September 1, 2016 to November 30, 2016 (inclusive). The transcripts were from
six shows from three networks, Fox News, MSNBC, and CNN. The shows were the
two most watched shows from each network for the month of
October, 2016 \cite{Katz2016}. The shows and their networks are listed in 
Table \ref{tab:shows}. 

\vspace{.2in}

\begin{table}[!htb]
  \centering
    \begin{tabular}{|c|c|}
      \hline
        Network & Programs \\
      \hline
      \multirow{2}{*}{Fox News} 
        & The O'Reilly Factor \\
        & The Kelly File \\
      \hline
      \multirow{2}{*}{MSNBC}
        & The Rachel Maddow Show \\
        & The Last Word with Lawrence O'Donnell \\
      \hline
      \multirow{2}{*}{CNN}
        & Anderson Cooper 360 \\
        & Erin Burnett OutFront \\
      \hline
    \end{tabular}
  \caption{List of shows used in corpus and their networks.}
  \label{tab:shows}
\end{table}

While the transcripts may be available on each network's website 
for each of the days in the study range, we don't depend on this.
Instead, we use the Internet Archive's (\url{http://archive.org}) 
TV News Archive, or TVNA for short (\url{http://archive.org/tv/details}).
There are several reasons that the TVNA is prefereable to scraping network
websites for transcripts.
First, there is no guarantee that everything said on the show
will be in the transcript. The transcripts used here are built from the
closed captioning recorded and stored in the TVNA. 
Second, the Internet Archive provides a stable, though hidden, API for 
programmatic access to the data stored there. Therefore, the software built
for corpus building does not have to scrape multiple websites, it only needs to
scrape one. Included with calls to the TVNA is a wealth of metadata on each
show including the original air date, run time, links back to the TVNA, and
clip download links. These are all used to build rich software for corpus
building and annotation as demonstrated below.


\subsection{Statistical Analysis}
\label{sub:statistical-analysis}

To review, the goal of the statistical analysis is to determine if and when
phase transitions occur to or from higher or lower frequency of use 
of figurative violence
during the campaign. Preliminary analyses of the data revealed that by far
the most commonly used violent words in figurative violence constructions were
\textit{attack}, \textit{hit}, and \textit{beat}. In order to have higher 
counts and increase statistical power, usages were summed across all programs,
so each day we counted the total number of uses of each one of those words.
There is a sampling of this data table in Table \ref{tab:sample-data}. In 
order to assign phases one, two, and three to each row of this table, we
must first decide what candidate dates we should use for the first and
second phase transition. Part of the analysis is to find what the optimal 
dates are in terms of relative likelihood that the model with two particular
phase transition dates captures more information than any other candidate
model, including the null hypothesis, or no dependence on phase.

\begin{table}[ht]
    \centering
    \begin{tabular}{|r|cc|}
        \hline
        date       &   facet    &  count     \\
        \hline
        2016-09-01 &     attack &    0     \\
        2016-09-02 &     hit    &    1     \\
        2016-09-03 &     hit    &    2     \\
        2016-09-04 &     beat   &    0     \\
        2016-09-05 &     beat   &    1     \\
        $\vdots$   &  $\vdots$  & $\vdots$ \\
    \end{tabular}
    \caption{Example first five rows of data used in statistical analysis to find
    phase transition before addition of phase}
    \label{tab:sample-data}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{|r|ccc|}
        \hline
        date       &  phase  &   facet    &  count     \\
        \hline               
        2016-09-01 &    1    &     attack &    0     \\
        2016-09-02 &    1    &     hit    &    1     \\
        2016-09-03 &    1    &     hit    &    2     \\
        2016-09-04 &    1    &     beat   &    0     \\
        2016-09-05 &    1    &     beat   &    1     \\
        $\vdots$   & $\vdots$&  $\vdots$  & $\vdots$ \\
    \end{tabular}
    \caption{Example first five rows of data used in statistical analysis to find
    phase transition with addition of phase}
    \label{tab:sample-data-wphase}
\end{table}


To model the data we used general linear mixed models, 
with \texttt{phase} and \texttt{facet} 
being fixed effects. Because the data is count data, Poisson regression was
used. Because there could be fluctuations on any given day,
\texttt{date} is modeled as a random effect. Including random effects are
preferred to simply averaging as this results in less information loss
\cite{Winter2013, Burnham2011, Clark1973}. Model generation was done with
the \texttt{lme4} R package \cite{Bates2015} called seamlessly 
from Python using the \texttt{rpy2} package \cite{Gautier2017}. To summarize,
the two basic models tested are given in Table \ref{tab:models}. The 
theoretical and methodological innovation presented here is in building 
a series of 266 models with 14 candidate dates for the first phase transition
and 19 candidate dates for the second phase transition\footnote{More were
tested in preliminary stages; these correspond to a more specific region of
interest}. In this way, we are actually comparing 267 models: one is the null
hypothesis, that there is no improvement in model performance if we do not
include phase in the model. The 266 other models include phase in the model,
but the dates where we assign each phase are shifted. We performed preliminary
analysis to determine that it was significant to add \texttt{facet} as a 
fixed effect.

\begin{table}[ht]
    \centering
    \begin{tabular}{|r|c|}
        \hline
        description & formula \\
        \hline
        null model, facet only & \texttt{count $\sim$ facet + (1|date)} \\
        includes phase       & \texttt{count $\sim$ phase + facet + (1|date)} \\
        \hline
    \end{tabular}
    \caption{Two basic models considered for modeling figurative violence usage}
    \label{tab:models}
\end{table}

While one could use the chi-square test and significance values to evaluate
the improvement from one model to another, this becomes unwieldy and 
questionable when comparing 267 models. A more modern approach is to compare
the Akaike information criterion (AIC) of the models 
\cite{Akaike1974, Burnham2004, Burnham2011}. The AIC is a measure of 
information loss in a model. It has no meaning on its own, but it is instead
used to calculate the likelihood that another candidate model minimizes 
information loss better than the model with minimum AIC, or 
AIC$_{\mathrm{min}}$. Comparing model $i$ with AIC larger than 
the model with AIC$_{\mathrm{min}}$ is done by calculating the 
the relative likelihood, given by

\begin{equation}
    \mathcal{L}_i = \exp{\left(
      \frac{\mathrm{AIC}_{\mathrm{min}} - \mathrm{AIC}_{i}}{2} 
      \right)
      }
  \label{eq:relative-likelihood}
\end{equation}

\noindent
so called because it yields the probability that model $i$ is actually the one
that results in a lower information loss than the model with AIC$_{\mathrm{min}}$.


In Section \ref{sec:Results}, Figures \ref{fig:AICs} and \ref{fig:relative-likelihoods}
show graphically the calculations of the AIC for all candidate phase
models and the relative likelihood of each candidate phase model, respectively.
